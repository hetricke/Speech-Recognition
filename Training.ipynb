{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from scipy.io import wavfile\n",
    "from tempfile import mktemp\n",
    "import itertools\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#1. Do the data normalizing thing. you know you gotta (Done!)\n",
    "#2. I think you need a better loss function- something that accounts for getting closer\n",
    "#3. Test different timesteps\n",
    "#4. Test different epochs\n",
    "#5. Test differet batch sizes\n",
    "\n",
    "#Original: Timestep = 2 Epoch = 2(?) Batch = 2(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 7\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 5\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS_FUNCTION = 'sparse_categorical_crossentropy'\n",
    "LETTER_CONVERSION = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q','r','s','t','u','v','w','x','y','z',' ','.', '' ]\n",
    "image_name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/hetricke/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/en/11.0.0/3f27acf10f303eac5b6fbbbe02495aeddb46ecffdb0a2fe3507fcfbf89094631)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "    trim_ms = 0 # ms\n",
    "\n",
    "    assert chunk_size > 0 # to avoid infinite loop\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "        trim_ms += chunk_size\n",
    "\n",
    "    return trim_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToNum(s):\n",
    "    try: \n",
    "        # print(\"original letter: \" + s)\n",
    "        # print(\"conversion number: \"+str(LETTER_CONVERSION.index(s)))\n",
    "        # print(\"conversion letter: \"+ convertToLetter(s))\n",
    "        # print()\n",
    "        return LETTER_CONVERSION.index(s)\n",
    "    except:\n",
    "        return 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToLetter(val):\n",
    "    try:\n",
    "        return LETTER_CONVERSION[val]\n",
    "    except:\n",
    "        return \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_prep(transcription):\n",
    "\n",
    "    if transcription.startswith('\"') and transcription.endswith('\"'):\n",
    "        # we can remove trailing quotation marks as they do not affect the transcription\n",
    "        transcription = transcription[1:-1]\n",
    "\n",
    "    transcription = transcription.lower()\n",
    "    \n",
    "    if len(transcription) > 0:\n",
    "        if transcription[-1] not in [\".\", \"?\", \"!\"]:\n",
    "            # append a full-stop to sentences that do not end in punctuation\n",
    "            transcription = transcription + \".\"\n",
    "\n",
    "    transcript_pieces = [convertToNum(c) for c in transcription]\n",
    "\n",
    "\n",
    "    return transcript_pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_file_prep(audio_path, sentence_length):\n",
    "\n",
    "    global image_name\n",
    "\n",
    "    #reads in mp3\n",
    "    mp3_audio = AudioSegment.from_file(audio_path, format=\"mp3\")  # read mp3\n",
    "\n",
    "    if(round(mp3_audio.duration_seconds) == 0):\n",
    "        return -1\n",
    "\n",
    "    #removes silent audio from the beginning and end\n",
    "    start_trim = detect_leading_silence(mp3_audio)\n",
    "    end_trim = detect_leading_silence(mp3_audio.reverse())\n",
    "    duration = len(mp3_audio)    \n",
    "    trimmed_sound = mp3_audio[start_trim:duration-end_trim]\n",
    "\n",
    "    #converts the mp3 into a wav file\n",
    "    wname = mktemp('.wav')  # use temporary file\n",
    "    trimmed_sound.export(wname, format=\"wav\")  # convert to wav\n",
    "    FS, audio_data = wavfile.read(wname)  # read wav file\n",
    "\n",
    "\n",
    "    #creates a file name for the spectrogram\n",
    "    file_name = \"images/\"+ str(image_name) + \".png\"\n",
    "    image_name = image_name + 1\n",
    "\n",
    "    #creates and saves the spectrogram\n",
    "    plt.figure()\n",
    "    plt.specgram(audio_data, Fs=FS, NFFT=128, noverlap=0)  # plot\n",
    "    plt.axis('off')\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "\n",
    "    #clears the figure for the next audio transcript- otherwise it just overwrites the image, which causes Problems\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    #loads the spectrogram and turns it into an array\n",
    "    img = keras.preprocessing.image.load_img(file_name)\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "\n",
    "    #slices the image array into appriopriate sizes for each chunk\n",
    "    features = int(img_array.shape[0]/sentence_length)\n",
    "    \n",
    "    divided_img_array = []\n",
    "    x_data = []\n",
    "    index = 0\n",
    "\n",
    "    for i in range(sentence_length):\n",
    "        feature_array = img_array[index:index+features]\n",
    "        new_dim = feature_array.shape[0]*feature_array.shape[1]\n",
    "        feature_array = feature_array.reshape(new_dim, -1)\n",
    "        feature_array = feature_array.flatten()\n",
    "        \n",
    "        padding = 33000-feature_array.shape[0]\n",
    "        feature_array = np.pad(feature_array, [(padding), (0)], mode='constant')\n",
    "\n",
    "        feature_array = feature_array.tolist()\n",
    "        feature_array[:] = [x / 255 for x in feature_array]\n",
    "\n",
    "        divided_img_array.append(feature_array)\n",
    "\n",
    "        index = index + features\n",
    "\n",
    "\n",
    "    half_timestep = int(TIME_STEPS/2)\n",
    "\n",
    "    for i in range(sentence_length):\n",
    "\n",
    "        start = i-half_timestep\n",
    "        end = i + half_timestep\n",
    "\n",
    "        start = start if (start >= 0) else 0\n",
    "        end = end if (end < len(divided_img_array)) else len(divided_img_array)-1\n",
    "\n",
    "        if(end-start < TIME_STEPS):\n",
    "\n",
    "            info = divided_img_array[start:end].copy()\n",
    "            null_list = [0]*(len(feature_array))\n",
    "\n",
    "\n",
    "            while len(info) < TIME_STEPS and start == 0:\n",
    "                info.insert(0, null_list.copy())\n",
    "\n",
    "            while len(info)<TIME_STEPS:\n",
    "                info.append(null_list.copy())\n",
    "\n",
    "    \n",
    "            x_data.append(info.copy())\n",
    "\n",
    "        else:\n",
    "            x_data.append(divided_img_array[start:end].copy())\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    #reshape the spectogram into a 3d array that goes (num samples x timesteps x features)\n",
    "    #1 sample is how many times this gets run through\n",
    "    #timesteps is how far backward to grab (so that's a value that can be played with!)\n",
    "    #num samples is I think how long it is (so grab the mp3 length)\n",
    "    #slice the image accordingly\n",
    "    #convert the image into an array (reference the obj detection) to use for the features\n",
    "    #profit\n",
    "\n",
    "    #so the min time is three, which, at 515 timesteps, gets 171.6666 columns of data per second\n",
    "    \n",
    "\n",
    "    return x_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = 0\n",
    "x_processed_data = []\n",
    "y_processed_data = []\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    x_processed_data.append(audio_file_prep(ds[i]['path'], len(ds[i][\"sentence\"])))\n",
    "    y_processed_data.append(transcript_prep(ds[i][\"sentence\"]))\n",
    "\n",
    "    if(x_processed_data[i] == -1 or len(y_processed_data[i])==0):\n",
    "       x_processed_data.pop(i)\n",
    "       y_processed_data.pop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102850/3883480599.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array(x_processed_data[:20])\n",
      "/tmp/ipykernel_102850/3883480599.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array(y_processed_data[:20])\n",
      "/tmp/ipykernel_102850/3883480599.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test = np.array(x_processed_data[20:25])\n",
      "/tmp/ipykernel_102850/3883480599.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array(y_processed_data[20:25])\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_processed_data[:20])\n",
    "y_train = np.array(y_processed_data[:20])\n",
    "\n",
    "x_test = np.array(x_processed_data[20:25])\n",
    "y_test = np.array(y_processed_data[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units = 128, activation = 'relu', input_shape = (TIME_STEPS, 33000)))\n",
    "model.add(keras.layers.Dense(units = 128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units = 128, activation ='relu'))\n",
    "model.add(keras.layers.SimpleRNN(units = 64, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(len(LETTER_CONVERSION)+1, activation = 'softmax'))\n",
    "model.compile(optimizer=OPTIMIZER, metrics=['accuracy'], loss=LOSS_FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 2s 53ms/step - loss: 3.7920 - accuracy: 0.0357\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 3.2730 - accuracy: 0.1607\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.3279 - accuracy: 0.1250\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.1863 - accuracy: 0.1071\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.9757 - accuracy: 0.1607\n",
      "1\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 1s 52ms/step - loss: 3.1353 - accuracy: 0.0978\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 1s 53ms/step - loss: 3.1134 - accuracy: 0.0761\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 1s 50ms/step - loss: 2.9647 - accuracy: 0.1196\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 2.8818 - accuracy: 0.1522\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 1s 61ms/step - loss: 2.9023 - accuracy: 0.0978\n",
      "2\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 3.0105 - accuracy: 0.1519\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 2.9382 - accuracy: 0.1772\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 47ms/step - loss: 2.8155 - accuracy: 0.1519\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.8248 - accuracy: 0.1646\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 2.8166 - accuracy: 0.1266\n",
      "3\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 3.1397 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 3.0383 - accuracy: 0.1625\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 2.9655 - accuracy: 0.1625\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 2.9337 - accuracy: 0.0875\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.8851 - accuracy: 0.1500\n",
      "4\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 3.1187 - accuracy: 0.1556\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 2.9400 - accuracy: 0.1556\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 2.7934 - accuracy: 0.1556\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 2.7574 - accuracy: 0.0889\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 2.5962 - accuracy: 0.0889\n",
      "5\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 3.0882 - accuracy: 0.1644\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 2.8931 - accuracy: 0.1781\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 2.8178 - accuracy: 0.1781\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 2.7793 - accuracy: 0.1918\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 2.7539 - accuracy: 0.1918\n",
      "6\n",
      "Epoch 1/5\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.9601 - accuracy: 0.2051\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 2.8692 - accuracy: 0.2051\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 2.7440 - accuracy: 0.2051\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.7043 - accuracy: 0.2051\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 2.6360 - accuracy: 0.2308\n",
      "7\n",
      "Epoch 1/5\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 3.0694 - accuracy: 0.1507\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 3.0177 - accuracy: 0.1507\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 2.9162 - accuracy: 0.1507\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 2.8110 - accuracy: 0.1644\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 2.8012 - accuracy: 0.1644\n",
      "8\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 2.9674 - accuracy: 0.1447\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 2.8823 - accuracy: 0.1447\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 2.8481 - accuracy: 0.1184\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 2.7395 - accuracy: 0.1579\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 2.7201 - accuracy: 0.1711\n",
      "9\n",
      "Epoch 1/5\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 2.9737 - accuracy: 0.1444\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 2.8935 - accuracy: 0.1444\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 2.7826 - accuracy: 0.1556\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 2.7640 - accuracy: 0.1556\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 2.7117 - accuracy: 0.1444\n",
      "10\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 3.1400 - accuracy: 0.1818\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 2.9318 - accuracy: 0.2121\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 2.6483 - accuracy: 0.1515\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 2.5598 - accuracy: 0.2424\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 2.4620 - accuracy: 0.2424\n",
      "11\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 3.0755 - accuracy: 0.1857\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 2.9354 - accuracy: 0.2000\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.8466 - accuracy: 0.2143\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 2.7042 - accuracy: 0.2000\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.7177 - accuracy: 0.2143\n",
      "12\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 2.9335 - accuracy: 0.1731\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 2.8469 - accuracy: 0.1731\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 2.7866 - accuracy: 0.1923\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 2.7468 - accuracy: 0.1923\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 2.7160 - accuracy: 0.1923\n",
      "13\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 2.9940 - accuracy: 0.1429\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 2.9373 - accuracy: 0.1429\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 2.8745 - accuracy: 0.1429\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.8263 - accuracy: 0.1429\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 2.7588 - accuracy: 0.1607\n",
      "14\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 2.9600 - accuracy: 0.1905\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 2.8906 - accuracy: 0.1905\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 2.8001 - accuracy: 0.1905\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 2.7809 - accuracy: 0.1905\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 2.7508 - accuracy: 0.2063\n",
      "15\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 2.8226 - accuracy: 0.2105\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 2.7503 - accuracy: 0.2281\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.6956 - accuracy: 0.2281\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 2.6472 - accuracy: 0.2281\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 2.6296 - accuracy: 0.2456\n",
      "16\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.7396 - accuracy: 0.2203\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.7252 - accuracy: 0.2203\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 2.6473 - accuracy: 0.2203\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 2.6224 - accuracy: 0.2203\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 2.5934 - accuracy: 0.2203\n",
      "17\n",
      "Epoch 1/5\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 2.9517 - accuracy: 0.1481\n",
      "Epoch 2/5\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 2.9298 - accuracy: 0.1358\n",
      "Epoch 3/5\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 2.9491 - accuracy: 0.1358\n",
      "Epoch 4/5\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 2.8938 - accuracy: 0.1358\n",
      "Epoch 5/5\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 2.8495 - accuracy: 0.1358\n",
      "18\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 2.8708 - accuracy: 0.1579\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 2.8313 - accuracy: 0.1053\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 50ms/step - loss: 2.7488 - accuracy: 0.1842\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 52ms/step - loss: 2.6953 - accuracy: 0.1842\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.6825 - accuracy: 0.1974\n",
      "19\n",
      "Epoch 1/5\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 2.7755 - accuracy: 0.1842\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 2.6855 - accuracy: 0.2368\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 2.5818 - accuracy: 0.2368\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.4983 - accuracy: 0.2632\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 2.4333 - accuracy: 0.2632\n"
     ]
    }
   ],
   "source": [
    "for recording in range(20):\n",
    "    print(recording)\n",
    "    model.fit(x_train[recording], y_train[recording], epochs=EPOCHS, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/12 [================>.............] - ETA: 0s - loss: 2.9194 - accuracy: 0.1714  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 16:51:20.751486: W tensorflow/core/grappler/utils/graph_view.cc:849] No registered '' OpKernel for CPU devices compatible with node {{node sequential_12/simple_rnn_12/while/body/_1/sequential_12/simple_rnn_12/while/simple_rnn_cell_12/Relu}}\n",
      "\t.  Registered:  <no registered kernels>\n",
      "\n",
      "2023-12-02 16:51:20.760076: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-toposort,tfg-shape-inference{graph-version=0},tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_12/simple_rnn_12/while/body/_1/sequential_12/simple_rnn_12/while/simple_rnn_cell_12/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2023-12-02 16:51:20.770148: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_12/simple_rnn_12/while/body/_1/sequential_12/simple_rnn_12/while/simple_rnn_cell_12/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2023-12-02 16:51:20.770562: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_12/simple_rnn_12/while/body/_1/sequential_12/simple_rnn_12/while/simple_rnn_cell_12/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2023-12-02 16:51:20.771141: W tensorflow/core/common_runtime/optimize_function_graph_utils.cc:475] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Node 'sequential_12/simple_rnn_12/while/body/_1/sequential_12/simple_rnn_12/while/simple_rnn_cell_12/Relu' does not specify an operation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 20ms/step - loss: 2.9243 - accuracy: 0.1333\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 3.0962 - accuracy: 0.0795\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.8899 - accuracy: 0.0923\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 2.7567 - accuracy: 0.1667\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 2.8910 - accuracy: 0.1268\n",
      "0.11972274333238601\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "total_accuracy = 0\n",
    "for i in range(len(x_test)):\n",
    "    score, accuracy = model.evaluate(x_test[i], y_test[i], batch_size=BATCH_SIZE)\n",
    "    total_score += score\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "total_score /= len(x_test)\n",
    "total_accuracy /= len(x_test)\n",
    "\n",
    "print(total_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
