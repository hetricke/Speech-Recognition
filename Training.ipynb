{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import os.path\n",
    "%run data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables that were altered to test for best architecture\n",
    "EPOCHS =1\n",
    "BATCH_SIZE = 1\n",
    "OPTIMIZER = 'rmsprop'\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "LATENT_DIM = 256\n",
    "STEP_SIZE = 10\n",
    "\n",
    "#Globals\n",
    "target_characters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q','r','s','t','u','v','w','x','y','z',' ']\n",
    "target_characters = sorted(target_characters)\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "image_name = 0\n",
    "x_processed_data = []\n",
    "y_processed_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ds): \n",
    "    global image_name\n",
    "    global x_processed_data\n",
    "    global y_processed_data\n",
    "    \n",
    "    image_name = 0\n",
    "    x_processed_data = []\n",
    "    y_processed_data = []\n",
    "    \n",
    "    for i in range(STEP_SIZE):\n",
    "        x_processed_data.append(audio_file_prep(ds[i]['path']))\n",
    "        y_processed_data.append(transcript_prep(ds[i][\"sentence\"]))\n",
    "\n",
    "\n",
    "        #if something about the data is bad, it is removed from the set\n",
    "        if(x_processed_data[len(x_processed_data)-1] == -1 or len(y_processed_data[len(y_processed_data)-1])==0):\n",
    "            x_processed_data.pop(len(x_processed_data)-1)\n",
    "            y_processed_data.pop(len(y_processed_data)-1)\n",
    "\n",
    "    num_encoder_tokens = 256\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "    max_encoder_seq_length = max(len(audio) for audio in x_processed_data)\n",
    "    max_decoder_seq_length = 200\n",
    "\n",
    "    encoder_input_data = np.zeros( (len(x_processed_data), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros( (len(y_processed_data), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "    decoder_target_data = np.zeros( (len(y_processed_data), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "    for i, (x_datapoint, y_datapoint) in enumerate(zip(x_processed_data, y_processed_data)):\n",
    "        for t, val in enumerate(x_datapoint):\n",
    "            encoder_input_data[i, t, int(val*255)] = 1.0\n",
    "        encoder_input_data[i, t + 1 :, 0] = 1.0\n",
    "        for t, char in enumerate(y_datapoint):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "        decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "        decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
    "\n",
    "    model = None\n",
    "    if(os.path.exists('./s2s_model.keras')):\n",
    "        model = keras.models.load_model(\"s2s_model.keras\")\n",
    "\n",
    "    else: \n",
    "        # Define an input sequence and process it.\n",
    "        encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "        encoder = keras.layers.LSTM(LATENT_DIM, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "        # We discard `encoder_outputs` and only keep the states.\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        # Set up the decoder, using `encoder_states` as initial state.\n",
    "        decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "        # We set up our decoder to return full output sequences,\n",
    "        # and to return internal states as well. We don't use the\n",
    "        # return states in the training model, but we will use them in inference.\n",
    "        decoder_lstm = keras.layers.LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "        decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        # Define the model that will turn\n",
    "        # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "        model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=[\"accuracy\"]\n",
    "        )\n",
    "    model.fit(\n",
    "        [encoder_input_data, decoder_input_data],\n",
    "        decoder_target_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.2,\n",
    "    )\n",
    "    # Save model\n",
    "    model.save(\"s2s_model.keras\")\n",
    "    print(\"Updated Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of for loop\n",
      "Data segment: train[110:120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_11_0 (/home/hetricke/.cache/huggingface/datasets/mozilla-foundation___common_voice_11_0/en/11.0.0/3f27acf10f303eac5b6fbbbe02495aeddb46ecffdb0a2fe3507fcfbf89094631)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hetricke/anaconda3/envs/speech_recog_env/lib/python3.11/site-packages/matplotlib/axes/_axes.py:7939: RuntimeWarning: divide by zero encountered in log10\n",
      "  Z = 10. * np.log10(spec)\n",
      "/home/hetricke/anaconda3/envs/speech_recog_env/lib/python3.11/site-packages/matplotlib/axes/_axes.py:7939: RuntimeWarning: divide by zero encountered in log10\n",
      "  Z = 10. * np.log10(spec)\n",
      "2023-12-09 10:48:34.061075: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-12-09 10:48:39.997123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-09 10:48:39.998742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-09 10:48:39.999849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-09 10:48:40.443208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-09 10:48:40.445057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-09 10:48:40.446369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-09 10:48:46.631605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-09 10:48:46.634188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-09 10:48:46.636921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-09 10:48:46.869000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-09 10:48:46.870779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-09 10:48:46.872392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "for data in range(110,100000,STEP_SIZE):\n",
    "    #dataset loaded from hugging face\n",
    "    print(\"Start of for loop\")\n",
    "    data_segment = 'train['+str(data)+\":\"+str(data+STEP_SIZE)+\"]\"\n",
    "    print(\"Data segment: \" + data_segment)\n",
    "    ds = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\",  split=data_segment)\n",
    "    print(\"Dataset loaded\")\n",
    "    train_model(ds)\n",
    "    print(\"Model Trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
